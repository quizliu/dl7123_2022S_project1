Namespace(batch_size=128, channel=27, crop=(32, 4), cuda=True, cutout=(1, 4), epoch=100, factor=0.1, flip=0.5, label_smoothing=0.2, learning_rate=0.001, lr_limit=0.0001, optimzer='adamw', patience=10, plot=False, progress_bar=False, resnet=[18, 18, 18], scheduler='plateau', test=False, threshold=0.01)
trainable parameters: 4917601
epoch 1, train loss 1.996, test loss 1.844, test acc 0.4216, lr 0.001
epoch 2, train loss 1.711, test loss 1.606, test acc 0.5775, lr 0.001
epoch 3, train loss 1.564, test loss 1.501, test acc 0.6449, lr 0.001
epoch 4, train loss 1.46, test loss 1.4, test acc 0.7083, lr 0.001
epoch 5, train loss 1.387, test loss 1.347, test acc 0.7389, lr 0.001
epoch 6, train loss 1.333, test loss 1.313, test acc 0.7642, lr 0.001
epoch 7, train loss 1.284, test loss 1.269, test acc 0.7865, lr 0.001
epoch 8, train loss 1.253, test loss 1.254, test acc 0.796, lr 0.001
epoch 9, train loss 1.223, test loss 1.231, test acc 0.8026, lr 0.001
epoch 10, train loss 1.201, test loss 1.214, test acc 0.8173, lr 0.001
epoch 11, train loss 1.184, test loss 1.202, test acc 0.8243, lr 0.001
epoch 12, train loss 1.163, test loss 1.191, test acc 0.8261, lr 0.001
epoch 13, train loss 1.147, test loss 1.169, test acc 0.84, lr 0.001
epoch 14, train loss 1.135, test loss 1.164, test acc 0.8462, lr 0.001
epoch 15, train loss 1.125, test loss 1.158, test acc 0.8456, lr 0.001
epoch 16, train loss 1.114, test loss 1.157, test acc 0.8455, lr 0.001
epoch 17, train loss 1.103, test loss 1.15, test acc 0.8478, lr 0.001
epoch 18, train loss 1.09, test loss 1.134, test acc 0.8609, lr 0.001
epoch 19, train loss 1.081, test loss 1.126, test acc 0.8618, lr 0.001
epoch 20, train loss 1.074, test loss 1.134, test acc 0.8578, lr 0.001
epoch 21, train loss 1.067, test loss 1.124, test acc 0.8622, lr 0.001
epoch 22, train loss 1.06, test loss 1.122, test acc 0.8619, lr 0.001
epoch 23, train loss 1.055, test loss 1.112, test acc 0.8704, lr 0.001
epoch 24, train loss 1.045, test loss 1.108, test acc 0.8713, lr 0.001
epoch 25, train loss 1.04, test loss 1.117, test acc 0.8708, lr 0.001
epoch 26, train loss 1.032, test loss 1.113, test acc 0.8705, lr 0.001
epoch 27, train loss 1.029, test loss 1.103, test acc 0.875, lr 0.001
epoch 28, train loss 1.023, test loss 1.104, test acc 0.877, lr 0.001
epoch 29, train loss 1.018, test loss 1.097, test acc 0.88, lr 0.001
epoch 30, train loss 1.013, test loss 1.115, test acc 0.8712, lr 0.001
epoch 31, train loss 1.007, test loss 1.092, test acc 0.8809, lr 0.001
epoch 32, train loss 1.002, test loss 1.101, test acc 0.8797, lr 0.001
epoch 33, train loss 0.9979, test loss 1.099, test acc 0.8801, lr 0.001
epoch 34, train loss 0.9955, test loss 1.089, test acc 0.8829, lr 0.001
epoch 35, train loss 0.9926, test loss 1.08, test acc 0.8903, lr 0.001
epoch 36, train loss 0.9869, test loss 1.092, test acc 0.8851, lr 0.001
epoch 37, train loss 0.9829, test loss 1.081, test acc 0.8891, lr 0.001
epoch 38, train loss 0.9775, test loss 1.088, test acc 0.8862, lr 0.001
epoch 39, train loss 0.9761, test loss 1.09, test acc 0.8871, lr 0.001
epoch 40, train loss 0.9739, test loss 1.085, test acc 0.8876, lr 0.001
epoch 41, train loss 0.9715, test loss 1.09, test acc 0.8872, lr 0.001
epoch 42, train loss 0.9698, test loss 1.083, test acc 0.8873, lr 0.001
epoch 43, train loss 0.9654, test loss 1.081, test acc 0.8876, lr 0.001
epoch 44, train loss 0.9619, test loss 1.078, test acc 0.8901, lr 0.001
epoch 45, train loss 0.9606, test loss 1.074, test acc 0.8935, lr 0.001
epoch 46, train loss 0.958, test loss 1.092, test acc 0.8838, lr 0.001
epoch 47, train loss 0.9259, test loss 1.057, test acc 0.9043, lr 0.0001
epoch 48, train loss 0.913, test loss 1.055, test acc 0.9064, lr 0.0001
epoch 49, train loss 0.9102, test loss 1.055, test acc 0.9073, lr 0.0001
epoch 50, train loss 0.908, test loss 1.052, test acc 0.9084, lr 0.0001
epoch 51, train loss 0.905, test loss 1.053, test acc 0.9098, lr 0.0001
epoch 52, train loss 0.9042, test loss 1.058, test acc 0.9079, lr 0.0001
epoch 53, train loss 0.9037, test loss 1.056, test acc 0.9098, lr 0.0001
epoch 54, train loss 0.9018, test loss 1.059, test acc 0.9086, lr 0.0001
epoch 55, train loss 0.9001, test loss 1.058, test acc 0.908, lr 0.0001
epoch 56, train loss 0.9005, test loss 1.058, test acc 0.9089, lr 0.0001
epoch 57, train loss 0.8976, test loss 1.058, test acc 0.9076, lr 0.0001
epoch 58, train loss 0.8966, test loss 1.059, test acc 0.9073, lr 0.0001
epoch 59, train loss 0.8962, test loss 1.06, test acc 0.9077, lr 0.0001
epoch 60, train loss 0.8962, test loss 1.061, test acc 0.9099, lr 0.0001
epoch 61, train loss 0.8954, test loss 1.058, test acc 0.909, lr 0.0001
epoch 62, train loss 0.8951, test loss 1.061, test acc 0.9072, lr 0.0001
epoch 63, train loss 0.8946, test loss 1.057, test acc 0.9097, lr 0.0001
epoch 64, train loss 0.8938, test loss 1.059, test acc 0.9095, lr 0.0001
epoch 65, train loss 0.8928, test loss 1.059, test acc 0.9095, lr 0.0001
epoch 66, train loss 0.8922, test loss 1.057, test acc 0.9084, lr 0.0001
epoch 67, train loss 0.8933, test loss 1.058, test acc 0.9104, lr 0.0001
epoch 68, train loss 0.8909, test loss 1.06, test acc 0.91, lr 0.0001
epoch 69, train loss 0.8914, test loss 1.062, test acc 0.9082, lr 0.0001
epoch 70, train loss 0.8909, test loss 1.064, test acc 0.9064, lr 0.0001
epoch 71, train loss 0.8902, test loss 1.062, test acc 0.9093, lr 0.0001
epoch 72, train loss 0.8903, test loss 1.064, test acc 0.9068, lr 0.0001
epoch 73, train loss 0.8898, test loss 1.063, test acc 0.9092, lr 0.0001
epoch 74, train loss 0.8889, test loss 1.067, test acc 0.9069, lr 0.0001
epoch 75, train loss 0.8896, test loss 1.062, test acc 0.909, lr 0.0001
epoch 76, train loss 0.8891, test loss 1.065, test acc 0.9064, lr 0.0001
epoch 77, train loss 0.8875, test loss 1.066, test acc 0.9091, lr 0.0001
epoch 78, train loss 0.8882, test loss 1.064, test acc 0.9082, lr 0.0001
epoch 79, train loss 0.8879, test loss 1.066, test acc 0.9078, lr 0.0001
epoch 80, train loss 0.8868, test loss 1.068, test acc 0.9072, lr 0.0001
epoch 81, train loss 0.8865, test loss 1.069, test acc 0.9075, lr 0.0001
epoch 82, train loss 0.8881, test loss 1.07, test acc 0.9053, lr 0.0001
epoch 83, train loss 0.8869, test loss 1.07, test acc 0.9053, lr 0.0001
epoch 84, train loss 0.8864, test loss 1.071, test acc 0.9068, lr 0.0001
epoch 85, train loss 0.8856, test loss 1.069, test acc 0.9074, lr 0.0001
epoch 86, train loss 0.8846, test loss 1.07, test acc 0.9067, lr 0.0001
epoch 87, train loss 0.8862, test loss 1.07, test acc 0.9068, lr 0.0001
epoch 88, train loss 0.8845, test loss 1.073, test acc 0.9058, lr 0.0001
epoch 89, train loss 0.8862, test loss 1.07, test acc 0.9063, lr 0.0001
epoch 90, train loss 0.8837, test loss 1.072, test acc 0.9058, lr 0.0001
epoch 91, train loss 0.8842, test loss 1.074, test acc 0.904, lr 0.0001
epoch 92, train loss 0.8848, test loss 1.072, test acc 0.906, lr 0.0001
epoch 93, train loss 0.8842, test loss 1.068, test acc 0.907, lr 0.0001
epoch 94, train loss 0.8838, test loss 1.07, test acc 0.9072, lr 0.0001
epoch 95, train loss 0.8842, test loss 1.072, test acc 0.9063, lr 0.0001
epoch 96, train loss 0.884, test loss 1.07, test acc 0.9078, lr 0.0001
epoch 97, train loss 0.8829, test loss 1.072, test acc 0.9053, lr 0.0001
epoch 98, train loss 0.8828, test loss 1.07, test acc 0.908, lr 0.0001
epoch 99, train loss 0.8844, test loss 1.069, test acc 0.9085, lr 0.0001
epoch 100, train loss 0.8824, test loss 1.071, test acc 0.9069, lr 0.0001
main uses: 10095.9716s